# Efficient Detection of Split Personalities in Malware

## 摘要

恶意程序是很多互联网安全威胁的主要原因. 为了对付每天都会发现的成百上千的新恶意软件, 安全公司与研究人员一依靠自动化工具提取恶意软件的行为特征. 与此同时恶意软件作者也想方设法的防止被检测.恶意软件通常也具备检查出虚拟测试环境的能力. 这时恶意软件会改变行为模式或者直接崩溃, 和在正常系统里运行相比, 恶意软件在虚拟测试环境中会表现出不同的行为.

一种透明检测平台(Ether, Cobra)的出现使得恶意软件更难以检测出测试环境, 另一些提出了使用某些技术去识别并通过恶意软件的检测. 两者都成功检测出恶意软件并使恶意软件的防范机制失效. 然而两者都导致了高性能开销, 这使得它们不适合做大批量的恶意软件分析.

这份论文中, 我们将介绍一种技术可以高效检查出恶意软件在测试环境中的异样行为. 原理很简单:　比较在测试环境中与参考机器上的样品行为．　然而一个强大有效的比较实现是有困难的．　我们将记录恶意软件与操作系统的交互并将此作为测试环境中给样品的回复．我们将通过实验演示，通过这个方法，可以有效检测出具有很强防范机制的恶意软件．

## 介绍

与日俱增的恶意软件数目使安全公司与研究人员投入更大的精力用以研发自动化的恶意软件检测工具, 这些工具通常在受限环境中(沙箱)运行未知软件, 监测未知程序的行为. 根据监测到的结果, 研究人员能够评估恶意软件的威胁程度以及制定相应防范策略. 当然恶意软件作者也会编写相应代码以防范被检测出来. 通过隐藏在自动检测系统中, 恶意软件可以运行更长一段时间.

为了阻挠自动侦察, 恶意软件作者开发出了很多方法去检查恶意软件分析工具和沙箱. 当恶意软件发现存在恶意软件分析工具, 通常会不执行恶意功能或是直接退出. 恶意软件依靠恶意软件分析工具的目标类型实现这类检测. 一种检测来自运行环境的输入以确定是否存在分析工具. 通常这类检查查找文件, 注册表, 或是分析工具进程. 第二种检测检查测试环境与真实环境的不同特征. 对于这些检测, CPU指令的细小变化或是定时属性都是恶意软件用来确定运行环境的因素.

要解决"反检测恶意软件", 研究人员探索出两种途径. 一种专注与开发更难以察觉的分析平台, Cobra是最早的透明分析系统之一. 这种系统在检测中执行动态的代码转换, 也就是说每段代码块在执行前被反编译并检查. 在这个过程中, 每条指令都会被Cobra检查并替换为一个安全的版本, 这被称为透明注入(stealth implant). 之后研究人员提出了Ether, 一个利用硬件虚拟化以保持对恶意软件不可见的系统.

Cobra和Ether都展示出了它们难以被现有的恶意软件所发现. 然而, 它们也导致了不可忽视的性能负担, 特别是在执行细粒度(fine-grained)分析时. 不幸的是, 对于Anubis所生产的分析工具以及类似系统, 要得到全面的分析报告, 这样级别的分析是必须的. 这是因为这些系统至少需要检查从额外的Windows API库函数到系统调用的所有参数, 而且在运行时还经常追踪额外的信息. 影响性能的主要原因是Cobra和Ether通过进程执行单个指令. 有趣的是, Ether的作者指出他们的细粒度(fine-grained)分析"不是用来做实时分析的", 于此同时Cobra的作者指出他们工具的表现"在交互分析局限之内." 鉴于这些局限, 这些系统不适合用来自动处理大容量的恶意软件分析. 例如, Anubis每天接受到几千个恶意软件样本, 而这个数字对于商业反恶意软件公司可能更大.

第二类途径是检测恶意软件在不同环境下的行为异常. 最近, 研究人员提出了一个工具, 用以比较恶意软件在正常系统中与虚拟分析环境中的运行情况. 运行结果的偏差被认为是由恶意软件的检查机制导致的. 这个理论中的基本想法是很有吸引力的, 它保证了一种通用的恶意软件检测机制, 即恶意软件在不同运行环境下的行为异常. 然而在实践中还有一些需要解决的问题, 有效的执行异常检测是很重要的, 而且任何异常应该仅仅由恶意软件自己的检测机制所引发. 不幸的是上述的工具难以解决这两个问题. 首先, 这个个工具使用Ether产生参考轨迹, 这导致了难以接受的性能损耗. 其次, 恶意软件样本只简单地执行了两次, 一次在分析环境中一次在参考环境中. 然而正如我们的实验所演示的那样, 即使没有反分析检测, 执行恶意软件样本也会导致不同的运行结果. 因此, 两次执行追踪的不同并不是检测是否为恶意软件的有效指标.

这篇论文中我们提出一种有效可靠的检测工具, 它能够检测在不同环境下行为不同的恶意软件, 即那些"人格分裂"的恶意软件. 为了执行检测, 我们利用基本的一个想法, 在给定相同输入的情况下, 程序在测试环境中与参考环境中的运行结果应一致. 更进一步说, 我们在参考环境里用内核驱动有效记录下那些在分析环境中被恶意软件样本所执行的系统调用(和它们的参数)的轨迹. 这份系统调用日志包含了输出参数(被程序输出和被系统接收的值)和输入参数(由系统提供并被程序接收的值). 下一步在测试环境中再进行一次. 我们的分析环境是修改版的Anubis, 这是一个系统模拟器Qemu的扩展. 根据系统调用日志, 我们可以提供与参考系统相同的输入参数. 这允许我们在给出相同信息的情况下, 检查系统输出(与它们的参数)是否与期望的相符. 由于输入是相同的, 因此我们期望结果的偏差是由恶意软件的检查机制所导致的, 并因此导致了恶意软件执行了不同的流程.

我们的Windows进程回放设备是这个分析环境的核心组件, 它功能全面并支持那些需要特殊处理的功能, 例如多线程, 存储器映射文件, 和延迟系统调用. 这对于处理复杂的Windows内部进程并使系统在面对真正的恶意软件时能够正常工作是必不可少的. 我们的实验结果显示这样该系统能够识别多种不同的反分析检测. 此外, 系统可以成功的执行(回放)不包含检测的程序, 而且能够检测出带有反分析检测的恶意软件.

这篇论文的主要价值如下:

- 我们提出了一种可信有效的方法去检测"人格分裂"的恶意软件. 通过比较分析系统环境下与参考环境下程序运行的系统调用跟踪记录, 我们可以检测出带有反分析能力的恶意软件.
- 我们完善了一种对Windows进程的全面回放设备, 这使得我们在分析环境下与参考环境下能以相同的输入执行程序.
- 我们演示了我们的工具可以检测出带有反分析能力的恶意软件, 甚至是那些能够逃避Anubis的恶意软件.

## 问题说明

自动恶意软件分析工具(如Anubis)的终极目标是尽可能完善对于恶意软件行为的理解能力. 在实践中, 这些恶意软件分析工具通常遵循一个动态的方法, 简单的执行一个未知程序, 监视运行时行为. 两个限制分析工具送回结果完整性的问题是测试范围是有限的而且恶意软件能够检测并逃避测试工具的检测. 为了解决第一个问题, 研究人员提出一种拓展方法, 探索多条执行流程或使用静态分析扫描未执行的代码区域.

为了解决恶意软件能够检测出分析工具的问题, 研究人员提出了难以被察觉的透明分析工具. 如前所诉, 这些工具是有效的并能高效的收集系统调用踪迹. 然而, 对于不仅包括系统调用的细粒度分析, 这些工具不得不依赖于一种对单指令检测记录的模式. 对于当下的恶意软件分析需要来说这太慢了, 难以应付每天上千个的恶意软件样本. 不幸的是, 想要得到完整全面的分析结果, Anubis和其他工具需要查看更多信息, 而不单是系统调用, 因此, 需要细粒度分析. 例如, Anubis检查Windows API库调用并跟踪数据流的依赖.

**透明恶意软件分析.** 一种可以被看作是对于恶意软件不可见的Anubis或其他类似工具的修改版. 为了检验是否奏效, 用不同恶意软件的反检测方法进行实验是很有用的. Ether的作者提出一个透明检测系统必须满足5个基本要求. 这个系统既是本篇论文所提出并由我们完善的技术, 在Anubis的章节中我们会讨论这几个基本要求.  然而这个讨论适用于所有在模拟器或虚拟环境下运行恶意软件的所有方法. 一些替代方法(如CWSandbox或Joebox)将其中一部分运行于恶意软件进程内或是与之运行在一个操作系统之下, 恶意软件于分析工具具有类似的权限级别, 这样的分析平台就不是透明的.

要做到透明首先分析工具必须比程序具有更高权限. 这个要求对于那些在模拟器或虚拟环境中运行目标的方法来说并不重要. 对第二个要求也是如此, 其指出所有由分析器引入的副作用不可被不具备权限的恶意软件操作所访问.

第三个要求规定分析器在不同环境下指令集语义不变. 这个条件很难被模拟器满足. 一个模拟器仅仅是一个复杂硬件设备的软件实现. 因此总是有可能检测出不同的. 先前的工作也确实指出了基于模拟器于真实CPU不同的CPU语义攻击, 这也可以被恶意软件所利用. 这类攻击利用未有记录的X86指令副作用或是找寻具体CPU的模式寄存器, 而这些在模拟器中是不存在的.

第四个要求规定异常处理必须透明. 这同样要求系统调用(包括系统调用的结果)在分析环境与真实环境下必须一致. Ether的作者称Anubis和其他精心设计的基于模拟器的系统能够满足这个条件. 然而在实践中, 有很多种方法检查操作系统环境中的工件以探测是否为模拟器. 包括特定进程, 驱动, 或是游客系统中的注册表值. 例如, 在一个典型的Windows VMware工作站中, 注册表包含超过300条包含字符串VMware的事件. 理论上隐藏这些工件是可行的, 但是实践中却非常困难. 有许多找寻游客系统中资源以确定是模拟器还是分析系统的攻击, 它们也被恶意软件所利用.

第五个要求声明, 对于一个透明恶意软件分析系统, 应当有一个统一的时间度量. 也就是说, 指令在模拟器下与真实环境下的运行时间应当相同. 显然这不可能, 模拟器或虚拟机上执行指令要比原生机器上更慢. 通过让尽可能多的频道通过一个运行计时进程, 计时攻击非常难以缓解. 事实上, 基于外部资源的输入的计时检测并不包含在诸如Ether系统的威胁模型里.

考虑到分析系统的复杂度以及CPU语义的范围, 环境, 以及恶意软件作者所掌握的计时攻击, 要让Anubis对单个检测透明显然是一场艰苦战斗. 同样, Garfinkel等人得出结论, 要让虚拟机与真实机器无法被区分是不切实际的. 因此, 我们设想一种更通用的解决方法. 我们的方法是一个两步处理.

**发觉人格分裂的恶意软件.** 第一步中我们检测是否有人格分裂的恶意软件. 这也是本篇论文所诉工具的关注点. 我们所诉工具在这里的目标是检测那些在分析环境中与参考环境中(不包含分析工具)表现不一致的恶意软件.
注意我们将一个模拟器(例如Anubis所使用的Qemu)看作是分析环境中的一部分. 这样我们的系统也能够识别那些检测Qemu的恶意软件. 程序行为由程序引用的系统调用(类型于参数)定义. 我们认为这是一个合理的假设, 因为系统调用是程序与环境的通讯手段, 它可以引起操作系统或是其他主机(通过网络)的持久性变化.

一个工具能够可靠有效的识别人格分裂的恶意软件是很重要的. 我们努力使系统没有漏报或错报. 漏报更加严重, 这意味着分析人格分裂的恶意软件失败了, 极有可能漏掉了一个严重威胁. 错报通常会导致性能损失, 因为人格分裂的恶意软件导致了额外的分析工作. 出于对性能的考虑, 我们要求探测器不要增加太多额外开销到现有的Anubis分析处理中. 目前, Anubis分析环境在两台物理机器上包含10个Qemu活动. 尽管机器得到了充分利用,  依然不安排它们处理我们每日的样本需求量. 因此, 在少量样本的情况下任何的开销增加都会立即被分析.

**处理人格分裂的恶意软件.** 第二步是利用发觉人格分裂恶意软件过程中收集到的信息改善分析结果. 一个可能性是在透明但是代价高昂的分析框架如Ether中重复运行恶意软件样本. 这种情况下我们所提出的系统作为一个高效可靠的过滤器去检查那些需要额外分析的恶意软件. 目前, 这种方法是实际可行的. 试图检测分析环境的恶意软件所占比例相当低. 例如, 在前面的工作中, 我们发现在Anubis数据库中低于1%的样本执行了已知的探测分析环境的检测或是被可被识别的保护程序(如Armadillo或tElock)打包或者在Qemu中崩溃. 这和一项相关研究的发现是一致的, 这个研究的作者证明约4%的恶意软件在虚拟机下表现出不同的行为. 然而随着比例的升高, 需要一个替代方案. 一个可能的场景是进行额外的分析以识别行为异样的根本原因. 一旦根本原因被发现(可能是恶意软件检测), 分析系统可以适应并自动绕过这样的检测. "emulationresistant"程序就遵循这样的方法, 其模拟技术正如上述.